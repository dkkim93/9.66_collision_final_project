
 dongki@dongki  ~/class/9.660/9.66_collision_final_project/neural_net   master ●  ls
ensemble_nn.py  main.py  normal_nn.py  __pycache__  utils.py
 dongki@dongki  ~/class/9.660/9.66_collision_final_project/neural_net   master ●  python3 main.py 
/home/dongki/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
input_data.shape: (8475, 20)
label_data.shape: (8475, 2)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 20)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                1344      
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 130       
=================================================================
Total params: 5,634
Trainable params: 5,634
Non-trainable params: 0
_________________________________________________________________
Train on 6780 samples, validate on 1695 samples
Epoch 1/250
2018-12-14 23:44:47.484951: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
6780/6780 [==============================] - 0s 23us/step - loss: 0.6332 - acc: 0.6640 - val_loss: 0.6058 - val_acc: 0.7027
Epoch 2/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.6006 - acc: 0.6864 - val_loss: 0.5920 - val_acc: 0.7056
Epoch 3/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5883 - acc: 0.6889 - val_loss: 0.5827 - val_acc: 0.7097
Epoch 4/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5786 - acc: 0.6972 - val_loss: 0.5743 - val_acc: 0.7121
Epoch 5/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5696 - acc: 0.7069 - val_loss: 0.5655 - val_acc: 0.7251
Epoch 6/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5604 - acc: 0.7190 - val_loss: 0.5556 - val_acc: 0.7428
Epoch 7/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5525 - acc: 0.7291 - val_loss: 0.5466 - val_acc: 0.7463
Epoch 8/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5432 - acc: 0.7394 - val_loss: 0.5396 - val_acc: 0.7634
Epoch 9/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5341 - acc: 0.7432 - val_loss: 0.5309 - val_acc: 0.7593
Epoch 10/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5247 - acc: 0.7503 - val_loss: 0.5228 - val_acc: 0.7611
Epoch 11/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5158 - acc: 0.7562 - val_loss: 0.5118 - val_acc: 0.7658
Epoch 12/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.5076 - acc: 0.7646 - val_loss: 0.5025 - val_acc: 0.7906
Epoch 13/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4963 - acc: 0.7751 - val_loss: 0.4965 - val_acc: 0.7841
Epoch 14/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4871 - acc: 0.7785 - val_loss: 0.4859 - val_acc: 0.8024
Epoch 15/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4762 - acc: 0.7900 - val_loss: 0.4748 - val_acc: 0.7947
Epoch 16/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4659 - acc: 0.7912 - val_loss: 0.4662 - val_acc: 0.8000
Epoch 17/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4563 - acc: 0.7956 - val_loss: 0.4563 - val_acc: 0.8024
Epoch 18/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4486 - acc: 0.7972 - val_loss: 0.4486 - val_acc: 0.8000
Epoch 19/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4387 - acc: 0.7997 - val_loss: 0.4456 - val_acc: 0.8018
Epoch 20/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4305 - acc: 0.8012 - val_loss: 0.4370 - val_acc: 0.8029
Epoch 21/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4229 - acc: 0.8065 - val_loss: 0.4262 - val_acc: 0.8142
Epoch 22/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4143 - acc: 0.8060 - val_loss: 0.4181 - val_acc: 0.8159
Epoch 23/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.4061 - acc: 0.8127 - val_loss: 0.4112 - val_acc: 0.8147
Epoch 24/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3985 - acc: 0.8173 - val_loss: 0.4068 - val_acc: 0.8136
Epoch 25/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3916 - acc: 0.8198 - val_loss: 0.3958 - val_acc: 0.8147
Epoch 26/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.3844 - acc: 0.8227 - val_loss: 0.3923 - val_acc: 0.8201
Epoch 27/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.3783 - acc: 0.8268 - val_loss: 0.3885 - val_acc: 0.8212
Epoch 28/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3726 - acc: 0.8268 - val_loss: 0.3815 - val_acc: 0.8242
Epoch 29/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.3674 - acc: 0.8294 - val_loss: 0.3805 - val_acc: 0.8177
Epoch 30/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3630 - acc: 0.8311 - val_loss: 0.3708 - val_acc: 0.8313
Epoch 31/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3569 - acc: 0.8383 - val_loss: 0.3689 - val_acc: 0.8254
Epoch 32/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.3513 - acc: 0.8376 - val_loss: 0.3625 - val_acc: 0.8360
Epoch 33/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3457 - acc: 0.8422 - val_loss: 0.3574 - val_acc: 0.8307
Epoch 34/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3435 - acc: 0.8437 - val_loss: 0.3518 - val_acc: 0.8366
Epoch 35/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.3375 - acc: 0.8466 - val_loss: 0.3552 - val_acc: 0.8295
Epoch 36/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3340 - acc: 0.8509 - val_loss: 0.3491 - val_acc: 0.8407
Epoch 37/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3301 - acc: 0.8529 - val_loss: 0.3426 - val_acc: 0.8366
Epoch 38/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.3257 - acc: 0.8541 - val_loss: 0.3420 - val_acc: 0.8383
Epoch 39/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3229 - acc: 0.8578 - val_loss: 0.3394 - val_acc: 0.8389
Epoch 40/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3195 - acc: 0.8572 - val_loss: 0.3354 - val_acc: 0.8442
Epoch 41/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3185 - acc: 0.8581 - val_loss: 0.3340 - val_acc: 0.8425
Epoch 42/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3133 - acc: 0.8599 - val_loss: 0.3301 - val_acc: 0.8383
Epoch 43/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3108 - acc: 0.8625 - val_loss: 0.3243 - val_acc: 0.8496
Epoch 44/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3094 - acc: 0.8628 - val_loss: 0.3259 - val_acc: 0.8507
Epoch 45/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3067 - acc: 0.8636 - val_loss: 0.3289 - val_acc: 0.8413
Epoch 46/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3023 - acc: 0.8647 - val_loss: 0.3151 - val_acc: 0.8537
Epoch 47/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.3016 - acc: 0.8640 - val_loss: 0.3154 - val_acc: 0.8543
Epoch 48/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2981 - acc: 0.8670 - val_loss: 0.3127 - val_acc: 0.8572
Epoch 49/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2958 - acc: 0.8695 - val_loss: 0.3125 - val_acc: 0.8619
Epoch 50/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2948 - acc: 0.8696 - val_loss: 0.3102 - val_acc: 0.8513
Epoch 51/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2930 - acc: 0.8711 - val_loss: 0.3144 - val_acc: 0.8454
Epoch 52/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2912 - acc: 0.8704 - val_loss: 0.3113 - val_acc: 0.8537
Epoch 53/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2884 - acc: 0.8739 - val_loss: 0.3055 - val_acc: 0.8673
Epoch 54/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2881 - acc: 0.8701 - val_loss: 0.3071 - val_acc: 0.8560
Epoch 55/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2853 - acc: 0.8748 - val_loss: 0.3036 - val_acc: 0.8643
Epoch 56/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2883 - acc: 0.8708 - val_loss: 0.3028 - val_acc: 0.8673
Epoch 57/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2827 - acc: 0.8746 - val_loss: 0.3053 - val_acc: 0.8655
Epoch 58/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2835 - acc: 0.8718 - val_loss: 0.3017 - val_acc: 0.8602
Epoch 59/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2813 - acc: 0.8755 - val_loss: 0.3022 - val_acc: 0.8649
Epoch 60/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2800 - acc: 0.8757 - val_loss: 0.2982 - val_acc: 0.8631
Epoch 61/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2785 - acc: 0.8733 - val_loss: 0.2952 - val_acc: 0.8673
Epoch 62/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2766 - acc: 0.8765 - val_loss: 0.2959 - val_acc: 0.8702
Epoch 63/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2762 - acc: 0.8752 - val_loss: 0.2939 - val_acc: 0.8678
Epoch 64/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2739 - acc: 0.8761 - val_loss: 0.2948 - val_acc: 0.8625
Epoch 65/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2751 - acc: 0.8780 - val_loss: 0.2930 - val_acc: 0.8614
Epoch 66/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2740 - acc: 0.8771 - val_loss: 0.2934 - val_acc: 0.8684
Epoch 67/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2712 - acc: 0.8798 - val_loss: 0.2912 - val_acc: 0.8702
Epoch 68/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2720 - acc: 0.8761 - val_loss: 0.2868 - val_acc: 0.8726
Epoch 69/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2699 - acc: 0.8774 - val_loss: 0.2897 - val_acc: 0.8708
Epoch 70/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2691 - acc: 0.8777 - val_loss: 0.2855 - val_acc: 0.8720
Epoch 71/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2703 - acc: 0.8780 - val_loss: 0.2904 - val_acc: 0.8631
Epoch 72/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2681 - acc: 0.8799 - val_loss: 0.2918 - val_acc: 0.8684
Epoch 73/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2667 - acc: 0.8795 - val_loss: 0.2875 - val_acc: 0.8737
Epoch 74/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2650 - acc: 0.8813 - val_loss: 0.2868 - val_acc: 0.8684
Epoch 75/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2645 - acc: 0.8820 - val_loss: 0.2870 - val_acc: 0.8661
Epoch 76/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2650 - acc: 0.8814 - val_loss: 0.2818 - val_acc: 0.8732
Epoch 77/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2641 - acc: 0.8820 - val_loss: 0.2859 - val_acc: 0.8720
Epoch 78/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2639 - acc: 0.8811 - val_loss: 0.2849 - val_acc: 0.8708
Epoch 79/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2628 - acc: 0.8835 - val_loss: 0.2870 - val_acc: 0.8649
Epoch 80/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2634 - acc: 0.8801 - val_loss: 0.2817 - val_acc: 0.8708
Epoch 81/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2623 - acc: 0.8805 - val_loss: 0.2831 - val_acc: 0.8714
Epoch 82/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2619 - acc: 0.8838 - val_loss: 0.2803 - val_acc: 0.8726
Epoch 83/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2606 - acc: 0.8816 - val_loss: 0.2841 - val_acc: 0.8720
Epoch 84/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2610 - acc: 0.8816 - val_loss: 0.2820 - val_acc: 0.8743
Epoch 85/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2631 - acc: 0.8798 - val_loss: 0.2819 - val_acc: 0.8702
Epoch 86/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2600 - acc: 0.8836 - val_loss: 0.2884 - val_acc: 0.8667
Epoch 87/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2590 - acc: 0.8814 - val_loss: 0.2822 - val_acc: 0.8743
Epoch 88/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2581 - acc: 0.8854 - val_loss: 0.2819 - val_acc: 0.8720
Epoch 89/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2579 - acc: 0.8838 - val_loss: 0.2821 - val_acc: 0.8649
Epoch 90/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2578 - acc: 0.8850 - val_loss: 0.2804 - val_acc: 0.8714
Epoch 91/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2575 - acc: 0.8819 - val_loss: 0.2843 - val_acc: 0.8661
Epoch 92/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2583 - acc: 0.8823 - val_loss: 0.2802 - val_acc: 0.8708
Epoch 93/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2565 - acc: 0.8827 - val_loss: 0.2810 - val_acc: 0.8732
Epoch 94/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2589 - acc: 0.8814 - val_loss: 0.2816 - val_acc: 0.8755
Epoch 95/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2549 - acc: 0.8857 - val_loss: 0.2821 - val_acc: 0.8732
Epoch 96/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2554 - acc: 0.8844 - val_loss: 0.2792 - val_acc: 0.8749
Epoch 97/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2559 - acc: 0.8822 - val_loss: 0.2851 - val_acc: 0.8708
Epoch 98/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2527 - acc: 0.8842 - val_loss: 0.2816 - val_acc: 0.8755
Epoch 99/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2529 - acc: 0.8844 - val_loss: 0.2799 - val_acc: 0.8743
Epoch 100/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2523 - acc: 0.8860 - val_loss: 0.2819 - val_acc: 0.8720
Epoch 101/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2522 - acc: 0.8838 - val_loss: 0.2826 - val_acc: 0.8720
Epoch 102/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2524 - acc: 0.8841 - val_loss: 0.2823 - val_acc: 0.8743
Epoch 103/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2509 - acc: 0.8867 - val_loss: 0.2828 - val_acc: 0.8714
Epoch 104/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2527 - acc: 0.8835 - val_loss: 0.2816 - val_acc: 0.8726
Epoch 105/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2506 - acc: 0.8870 - val_loss: 0.2761 - val_acc: 0.8767
Epoch 106/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2524 - acc: 0.8842 - val_loss: 0.2786 - val_acc: 0.8726
Epoch 107/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2506 - acc: 0.8855 - val_loss: 0.2735 - val_acc: 0.8767
Epoch 108/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2501 - acc: 0.8869 - val_loss: 0.2746 - val_acc: 0.8767
Epoch 109/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2493 - acc: 0.8850 - val_loss: 0.2791 - val_acc: 0.8737
Epoch 110/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2501 - acc: 0.8864 - val_loss: 0.2744 - val_acc: 0.8743
Epoch 111/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2484 - acc: 0.8869 - val_loss: 0.2773 - val_acc: 0.8761
Epoch 112/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2488 - acc: 0.8869 - val_loss: 0.2756 - val_acc: 0.8737
Epoch 113/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2485 - acc: 0.8879 - val_loss: 0.2773 - val_acc: 0.8743
Epoch 114/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2489 - acc: 0.8857 - val_loss: 0.2765 - val_acc: 0.8737
Epoch 115/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2468 - acc: 0.8894 - val_loss: 0.2752 - val_acc: 0.8732
Epoch 116/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2469 - acc: 0.8872 - val_loss: 0.2877 - val_acc: 0.8631
Epoch 117/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2470 - acc: 0.8876 - val_loss: 0.2863 - val_acc: 0.8678
Epoch 118/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2473 - acc: 0.8878 - val_loss: 0.2794 - val_acc: 0.8714
Epoch 119/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2469 - acc: 0.8864 - val_loss: 0.2803 - val_acc: 0.8732
Epoch 120/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2457 - acc: 0.8895 - val_loss: 0.2756 - val_acc: 0.8743
Epoch 121/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2462 - acc: 0.8855 - val_loss: 0.2727 - val_acc: 0.8755
Epoch 122/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2482 - acc: 0.8866 - val_loss: 0.2740 - val_acc: 0.8732
Epoch 123/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2457 - acc: 0.8881 - val_loss: 0.2737 - val_acc: 0.8773
Epoch 124/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2442 - acc: 0.8879 - val_loss: 0.2748 - val_acc: 0.8732
Epoch 125/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2444 - acc: 0.8881 - val_loss: 0.2752 - val_acc: 0.8732
Epoch 126/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2453 - acc: 0.8872 - val_loss: 0.2721 - val_acc: 0.8773
Epoch 127/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2444 - acc: 0.8876 - val_loss: 0.2776 - val_acc: 0.8696
Epoch 128/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2458 - acc: 0.8835 - val_loss: 0.2769 - val_acc: 0.8737
Epoch 129/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2457 - acc: 0.8875 - val_loss: 0.2730 - val_acc: 0.8767
Epoch 130/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2428 - acc: 0.8894 - val_loss: 0.2782 - val_acc: 0.8737
Epoch 131/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2429 - acc: 0.8886 - val_loss: 0.2766 - val_acc: 0.8755
Epoch 132/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2427 - acc: 0.8897 - val_loss: 0.2736 - val_acc: 0.8726
Epoch 133/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2437 - acc: 0.8870 - val_loss: 0.2762 - val_acc: 0.8773
Epoch 134/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2429 - acc: 0.8889 - val_loss: 0.2806 - val_acc: 0.8667
Epoch 135/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2430 - acc: 0.8882 - val_loss: 0.2801 - val_acc: 0.8743
Epoch 136/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2432 - acc: 0.8870 - val_loss: 0.2785 - val_acc: 0.8714
Epoch 137/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2434 - acc: 0.8857 - val_loss: 0.2763 - val_acc: 0.8673
Epoch 138/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2441 - acc: 0.8873 - val_loss: 0.2780 - val_acc: 0.8678
Epoch 139/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2416 - acc: 0.8881 - val_loss: 0.2824 - val_acc: 0.8649
Epoch 140/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2420 - acc: 0.8866 - val_loss: 0.2738 - val_acc: 0.8702
Epoch 141/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2405 - acc: 0.8900 - val_loss: 0.2896 - val_acc: 0.8519
Epoch 142/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2431 - acc: 0.8830 - val_loss: 0.2748 - val_acc: 0.8720
Epoch 143/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2431 - acc: 0.8869 - val_loss: 0.2739 - val_acc: 0.8732
Epoch 144/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2417 - acc: 0.8870 - val_loss: 0.2746 - val_acc: 0.8708
Epoch 145/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2389 - acc: 0.8898 - val_loss: 0.2788 - val_acc: 0.8619
Epoch 146/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2397 - acc: 0.8886 - val_loss: 0.2768 - val_acc: 0.8714
Epoch 147/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2384 - acc: 0.8898 - val_loss: 0.2817 - val_acc: 0.8673
Epoch 148/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2381 - acc: 0.8891 - val_loss: 0.2768 - val_acc: 0.8743
Epoch 149/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2388 - acc: 0.8878 - val_loss: 0.2790 - val_acc: 0.8667
Epoch 150/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2397 - acc: 0.8892 - val_loss: 0.2748 - val_acc: 0.8702
Epoch 151/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2392 - acc: 0.8873 - val_loss: 0.2721 - val_acc: 0.8720
Epoch 152/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2369 - acc: 0.8904 - val_loss: 0.2715 - val_acc: 0.8714
Epoch 153/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2386 - acc: 0.8895 - val_loss: 0.2771 - val_acc: 0.8667
Epoch 154/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2381 - acc: 0.8894 - val_loss: 0.2823 - val_acc: 0.8614
Epoch 155/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2377 - acc: 0.8894 - val_loss: 0.2769 - val_acc: 0.8714
Epoch 156/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2388 - acc: 0.8869 - val_loss: 0.2772 - val_acc: 0.8767
Epoch 157/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2351 - acc: 0.8891 - val_loss: 0.2756 - val_acc: 0.8720
Epoch 158/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2353 - acc: 0.8916 - val_loss: 0.2737 - val_acc: 0.8702
Epoch 159/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2361 - acc: 0.8897 - val_loss: 0.2800 - val_acc: 0.8661
Epoch 160/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2387 - acc: 0.8882 - val_loss: 0.2742 - val_acc: 0.8732
Epoch 161/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2366 - acc: 0.8885 - val_loss: 0.2781 - val_acc: 0.8702
Epoch 162/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2365 - acc: 0.8881 - val_loss: 0.2769 - val_acc: 0.8761
Epoch 163/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2361 - acc: 0.8881 - val_loss: 0.2736 - val_acc: 0.8702
Epoch 164/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2375 - acc: 0.8886 - val_loss: 0.2838 - val_acc: 0.8720
Epoch 165/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2389 - acc: 0.8866 - val_loss: 0.2720 - val_acc: 0.8708
Epoch 166/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2363 - acc: 0.8901 - val_loss: 0.2762 - val_acc: 0.8732
Epoch 167/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2357 - acc: 0.8895 - val_loss: 0.2732 - val_acc: 0.8755
Epoch 168/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2346 - acc: 0.8917 - val_loss: 0.2748 - val_acc: 0.8661
Epoch 169/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2363 - acc: 0.8883 - val_loss: 0.2739 - val_acc: 0.8714
Epoch 170/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2342 - acc: 0.8900 - val_loss: 0.2790 - val_acc: 0.8614
Epoch 171/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2333 - acc: 0.8914 - val_loss: 0.2812 - val_acc: 0.8655
Epoch 172/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2346 - acc: 0.8898 - val_loss: 0.2843 - val_acc: 0.8590
Epoch 173/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2347 - acc: 0.8910 - val_loss: 0.2784 - val_acc: 0.8625
Epoch 174/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2350 - acc: 0.8906 - val_loss: 0.2724 - val_acc: 0.8761
Epoch 175/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2338 - acc: 0.8904 - val_loss: 0.2777 - val_acc: 0.8696
Epoch 176/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2348 - acc: 0.8903 - val_loss: 0.2709 - val_acc: 0.8702
Epoch 177/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2320 - acc: 0.8894 - val_loss: 0.2763 - val_acc: 0.8702
Epoch 178/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2329 - acc: 0.8897 - val_loss: 0.2804 - val_acc: 0.8661
Epoch 179/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2324 - acc: 0.8888 - val_loss: 0.2771 - val_acc: 0.8737
Epoch 180/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2321 - acc: 0.8916 - val_loss: 0.2744 - val_acc: 0.8708
Epoch 181/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2343 - acc: 0.8912 - val_loss: 0.2838 - val_acc: 0.8496
Epoch 182/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2346 - acc: 0.8883 - val_loss: 0.2735 - val_acc: 0.8726
Epoch 183/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2334 - acc: 0.8888 - val_loss: 0.2766 - val_acc: 0.8661
Epoch 184/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2331 - acc: 0.8895 - val_loss: 0.2785 - val_acc: 0.8755
Epoch 185/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2337 - acc: 0.8894 - val_loss: 0.2711 - val_acc: 0.8720
Epoch 186/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2321 - acc: 0.8917 - val_loss: 0.2822 - val_acc: 0.8655
Epoch 187/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2324 - acc: 0.8916 - val_loss: 0.2710 - val_acc: 0.8714
Epoch 188/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2318 - acc: 0.8920 - val_loss: 0.2755 - val_acc: 0.8673
Epoch 189/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2327 - acc: 0.8892 - val_loss: 0.2747 - val_acc: 0.8714
Epoch 190/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2314 - acc: 0.8886 - val_loss: 0.2741 - val_acc: 0.8714
Epoch 191/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2300 - acc: 0.8912 - val_loss: 0.2758 - val_acc: 0.8732
Epoch 192/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2319 - acc: 0.8894 - val_loss: 0.2768 - val_acc: 0.8714
Epoch 193/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2313 - acc: 0.8906 - val_loss: 0.2769 - val_acc: 0.8755
Epoch 194/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2320 - acc: 0.8883 - val_loss: 0.2772 - val_acc: 0.8720
Epoch 195/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2322 - acc: 0.8895 - val_loss: 0.2855 - val_acc: 0.8726
Epoch 196/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2323 - acc: 0.8913 - val_loss: 0.2736 - val_acc: 0.8737
Epoch 197/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2296 - acc: 0.8916 - val_loss: 0.2783 - val_acc: 0.8584
Epoch 198/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2315 - acc: 0.8904 - val_loss: 0.2725 - val_acc: 0.8732
Epoch 199/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2314 - acc: 0.8910 - val_loss: 0.2798 - val_acc: 0.8720
Epoch 200/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2304 - acc: 0.8898 - val_loss: 0.2773 - val_acc: 0.8678
Epoch 201/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2280 - acc: 0.8940 - val_loss: 0.2806 - val_acc: 0.8631
Epoch 202/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2297 - acc: 0.8920 - val_loss: 0.2741 - val_acc: 0.8655
Epoch 203/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2284 - acc: 0.8913 - val_loss: 0.2756 - val_acc: 0.8673
Epoch 204/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2299 - acc: 0.8912 - val_loss: 0.2819 - val_acc: 0.8714
Epoch 205/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2301 - acc: 0.8945 - val_loss: 0.2812 - val_acc: 0.8549
Epoch 206/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2334 - acc: 0.8885 - val_loss: 0.2826 - val_acc: 0.8661
Epoch 207/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2292 - acc: 0.8913 - val_loss: 0.2747 - val_acc: 0.8684
Epoch 208/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2293 - acc: 0.8909 - val_loss: 0.2713 - val_acc: 0.8690
Epoch 209/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2289 - acc: 0.8932 - val_loss: 0.2763 - val_acc: 0.8643
Epoch 210/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2274 - acc: 0.8935 - val_loss: 0.2725 - val_acc: 0.8737
Epoch 211/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2284 - acc: 0.8906 - val_loss: 0.2795 - val_acc: 0.8696
Epoch 212/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2278 - acc: 0.8917 - val_loss: 0.2724 - val_acc: 0.8737
Epoch 213/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2299 - acc: 0.8914 - val_loss: 0.2796 - val_acc: 0.8708
Epoch 214/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2290 - acc: 0.8909 - val_loss: 0.2828 - val_acc: 0.8625
Epoch 215/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2299 - acc: 0.8910 - val_loss: 0.2746 - val_acc: 0.8708
Epoch 216/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2301 - acc: 0.8914 - val_loss: 0.2850 - val_acc: 0.8720
Epoch 217/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2279 - acc: 0.8934 - val_loss: 0.2746 - val_acc: 0.8737
Epoch 218/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2290 - acc: 0.8912 - val_loss: 0.2751 - val_acc: 0.8696
Epoch 219/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2278 - acc: 0.8916 - val_loss: 0.2737 - val_acc: 0.8732
Epoch 220/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2280 - acc: 0.8889 - val_loss: 0.2793 - val_acc: 0.8749
Epoch 221/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2268 - acc: 0.8901 - val_loss: 0.2850 - val_acc: 0.8566
Epoch 222/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2308 - acc: 0.8854 - val_loss: 0.2738 - val_acc: 0.8755
Epoch 223/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2278 - acc: 0.8934 - val_loss: 0.2773 - val_acc: 0.8643
Epoch 224/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2277 - acc: 0.8914 - val_loss: 0.2759 - val_acc: 0.8678
Epoch 225/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2269 - acc: 0.8951 - val_loss: 0.2799 - val_acc: 0.8732
Epoch 226/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2266 - acc: 0.8945 - val_loss: 0.2743 - val_acc: 0.8690
Epoch 227/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2261 - acc: 0.8942 - val_loss: 0.2731 - val_acc: 0.8737
Epoch 228/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2255 - acc: 0.8928 - val_loss: 0.2757 - val_acc: 0.8732
Epoch 229/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2255 - acc: 0.8920 - val_loss: 0.2805 - val_acc: 0.8708
Epoch 230/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2247 - acc: 0.8926 - val_loss: 0.2737 - val_acc: 0.8732
Epoch 231/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2255 - acc: 0.8917 - val_loss: 0.2770 - val_acc: 0.8720
Epoch 232/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2255 - acc: 0.8937 - val_loss: 0.2850 - val_acc: 0.8702
Epoch 233/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2275 - acc: 0.8925 - val_loss: 0.2720 - val_acc: 0.8708
Epoch 234/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2284 - acc: 0.8916 - val_loss: 0.2789 - val_acc: 0.8708
Epoch 235/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2296 - acc: 0.8892 - val_loss: 0.2858 - val_acc: 0.8696
Epoch 236/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2244 - acc: 0.8931 - val_loss: 0.2770 - val_acc: 0.8737
Epoch 237/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2248 - acc: 0.8948 - val_loss: 0.2783 - val_acc: 0.8708
Epoch 238/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2257 - acc: 0.8947 - val_loss: 0.2751 - val_acc: 0.8743
Epoch 239/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2243 - acc: 0.8945 - val_loss: 0.2788 - val_acc: 0.8690
Epoch 240/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2246 - acc: 0.8928 - val_loss: 0.2800 - val_acc: 0.8684
Epoch 241/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2243 - acc: 0.8926 - val_loss: 0.2804 - val_acc: 0.8690
Epoch 242/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2248 - acc: 0.8928 - val_loss: 0.2779 - val_acc: 0.8678
Epoch 243/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2244 - acc: 0.8926 - val_loss: 0.2736 - val_acc: 0.8732
Epoch 244/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2250 - acc: 0.8935 - val_loss: 0.2816 - val_acc: 0.8655
Epoch 245/250
6780/6780 [==============================] - 0s 7us/step - loss: 0.2254 - acc: 0.8929 - val_loss: 0.2815 - val_acc: 0.8673
Epoch 246/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2262 - acc: 0.8897 - val_loss: 0.2813 - val_acc: 0.8732
Epoch 247/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2250 - acc: 0.8922 - val_loss: 0.2784 - val_acc: 0.8720
Epoch 248/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2262 - acc: 0.8925 - val_loss: 0.2789 - val_acc: 0.8655
Epoch 249/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2239 - acc: 0.8938 - val_loss: 0.2755 - val_acc: 0.8749
Epoch 250/250
6780/6780 [==============================] - 0s 6us/step - loss: 0.2251 - acc: 0.8931 - val_loss: 0.2780 - val_acc: 0.8673
input_data.shape: (89, 20)
label_data.shape: (89, 2)
Data 0: no collision prob 0.01243 vs collision prob 0.98757
Data 1: no collision prob 0.34545 vs collision prob 0.65455
Data 2: no collision prob 0.06081 vs collision prob 0.93919
Data 3: no collision prob 0.27718 vs collision prob 0.72282
Data 4: no collision prob 0.30223 vs collision prob 0.69777
Data 5: no collision prob 1.00000 vs collision prob 0.00000
Data 6: no collision prob 0.99936 vs collision prob 0.00064
Data 7: no collision prob 0.99998 vs collision prob 0.00002
Data 8: no collision prob 0.99942 vs collision prob 0.00058
Data 9: no collision prob 0.25340 vs collision prob 0.74660
Data 10: no collision prob 0.99999 vs collision prob 0.00001
Data 11: no collision prob 0.99996 vs collision prob 0.00004
Data 12: no collision prob 0.16109 vs collision prob 0.83891
Data 13: no collision prob 0.99999 vs collision prob 0.00001
Data 14: no collision prob 0.27702 vs collision prob 0.72298
Data 15: no collision prob 0.44672 vs collision prob 0.55328
Data 16: no collision prob 0.00490 vs collision prob 0.99510
Data 17: no collision prob 0.98873 vs collision prob 0.01127
Data 18: no collision prob 1.00000 vs collision prob 0.00000
Data 19: no collision prob 0.27336 vs collision prob 0.72664
Data 20: no collision prob 0.99323 vs collision prob 0.00677
Data 21: no collision prob 0.99559 vs collision prob 0.00441
Data 22: no collision prob 0.97690 vs collision prob 0.02310
Data 23: no collision prob 1.00000 vs collision prob 0.00000
Data 24: no collision prob 0.99959 vs collision prob 0.00041
Data 25: no collision prob 0.99992 vs collision prob 0.00008
Data 26: no collision prob 0.99999 vs collision prob 0.00001
Data 27: no collision prob 0.13653 vs collision prob 0.86347
Data 28: no collision prob 0.18345 vs collision prob 0.81655
Data 29: no collision prob 0.37059 vs collision prob 0.62941
Data 30: no collision prob 0.30687 vs collision prob 0.69313
Data 31: no collision prob 1.00000 vs collision prob 0.00000
Data 32: no collision prob 0.88749 vs collision prob 0.11251
Data 33: no collision prob 0.99969 vs collision prob 0.00031
Data 34: no collision prob 0.10742 vs collision prob 0.89258
Data 35: no collision prob 0.99706 vs collision prob 0.00294
Data 36: no collision prob 0.04130 vs collision prob 0.95870
Data 37: no collision prob 0.99999 vs collision prob 0.00001
Data 38: no collision prob 0.33332 vs collision prob 0.66668
Data 39: no collision prob 1.00000 vs collision prob 0.00000
Data 40: no collision prob 0.99997 vs collision prob 0.00003
Data 41: no collision prob 1.00000 vs collision prob 0.00000
Data 42: no collision prob 0.15394 vs collision prob 0.84606
Data 43: no collision prob 0.99997 vs collision prob 0.00003
Data 44: no collision prob 0.99913 vs collision prob 0.00087
Data 45: no collision prob 0.62163 vs collision prob 0.37837
Data 46: no collision prob 0.99995 vs collision prob 0.00005
Data 47: no collision prob 0.34771 vs collision prob 0.65229
Data 48: no collision prob 0.99999 vs collision prob 0.00001
Data 49: no collision prob 0.99997 vs collision prob 0.00003
Data 50: no collision prob 0.99871 vs collision prob 0.00129
Data 51: no collision prob 1.00000 vs collision prob 0.00000
Data 52: no collision prob 0.00599 vs collision prob 0.99401
Data 53: no collision prob 0.99888 vs collision prob 0.00112
Data 54: no collision prob 0.20364 vs collision prob 0.79636
Data 55: no collision prob 0.96217 vs collision prob 0.03783
Data 56: no collision prob 0.97839 vs collision prob 0.02161
Data 57: no collision prob 0.99598 vs collision prob 0.00402
Data 58: no collision prob 0.38032 vs collision prob 0.61968
Data 59: no collision prob 0.94835 vs collision prob 0.05165
Data 60: no collision prob 1.00000 vs collision prob 0.00000
Data 61: no collision prob 0.39891 vs collision prob 0.60109
Data 62: no collision prob 0.99998 vs collision prob 0.00002
Data 63: no collision prob 1.00000 vs collision prob 0.00000
Data 64: no collision prob 0.14688 vs collision prob 0.85312
Data 65: no collision prob 0.99895 vs collision prob 0.00105
Data 66: no collision prob 0.09426 vs collision prob 0.90574
Data 67: no collision prob 0.99877 vs collision prob 0.00123
Data 68: no collision prob 1.00000 vs collision prob 0.00000
Data 69: no collision prob 0.00597 vs collision prob 0.99403
Data 70: no collision prob 0.00627 vs collision prob 0.99373
Data 71: no collision prob 0.99983 vs collision prob 0.00017
Data 72: no collision prob 0.35430 vs collision prob 0.64570
Data 73: no collision prob 0.01951 vs collision prob 0.98049
Data 74: no collision prob 0.78924 vs collision prob 0.21076
Data 75: no collision prob 0.99847 vs collision prob 0.00153
Data 76: no collision prob 0.99995 vs collision prob 0.00005
Data 77: no collision prob 0.39381 vs collision prob 0.60619
Data 78: no collision prob 1.00000 vs collision prob 0.00000
Data 79: no collision prob 0.01288 vs collision prob 0.98712
Data 80: no collision prob 1.00000 vs collision prob 0.00000
Data 81: no collision prob 0.99970 vs collision prob 0.00030
Data 82: no collision prob 1.00000 vs collision prob 0.00000
Data 83: no collision prob 1.00000 vs collision prob 0.00000
Data 84: no collision prob 0.33086 vs collision prob 0.66914
Data 85: no collision prob 1.00000 vs collision prob 0.00000
Data 86: no collision prob 1.00000 vs collision prob 0.00000
Data 87: no collision prob 1.00000 vs collision prob 0.00000
Data 88: no collision prob 1.00000 vs collision prob 0.00000
