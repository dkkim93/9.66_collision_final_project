ls%                                                                                                                                                           
 dongki@dongki  ~/class/9.660/9.66_collision_final_project/neural_net   master ●  ls
analysis.py  ensemble_nn.py  main.py  normal_nn.py  __pycache__  result_ensemble.txt  result_nn.txt  teacher_reward_analysis.py  utils.py
 dongki@dongki  ~/class/9.660/9.66_collision_final_project/neural_net   master ●  vim main.py q
2 files to edit
 dongki@dongki  ~/class/9.660/9.66_collision_final_project/neural_net   master ●  pythohn3 
 ✘ dongki@dongki  ~/class/9.660/9.66_collision_final_project/neural_net   master ●  python3 main.py 
/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
input_data.shape: (8475, 20)
label_data.shape: (8475, 2)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 20)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                1344      
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 130       
=================================================================
Total params: 5,634
Trainable params: 5,634
Non-trainable params: 0
_________________________________________________________________
Train on 6780 samples, validate on 1695 samples
Epoch 1/100
2018-12-16 15:14:39.287339: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
6780/6780 [==============================] - 1s 108us/step - loss: 0.6221 - acc: 0.6668 - val_loss: 0.5978 - val_acc: 0.7003
Epoch 2/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5988 - acc: 0.6813 - val_loss: 0.5877 - val_acc: 0.7009
Epoch 3/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5877 - acc: 0.6851 - val_loss: 0.5801 - val_acc: 0.7121
Epoch 4/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5782 - acc: 0.6945 - val_loss: 0.5733 - val_acc: 0.7204
Epoch 5/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5701 - acc: 0.7072 - val_loss: 0.5628 - val_acc: 0.7345
Epoch 6/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5623 - acc: 0.7205 - val_loss: 0.5566 - val_acc: 0.7392
Epoch 7/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5537 - acc: 0.7265 - val_loss: 0.5487 - val_acc: 0.7445
Epoch 8/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5471 - acc: 0.7357 - val_loss: 0.5401 - val_acc: 0.7534
Epoch 9/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5374 - acc: 0.7456 - val_loss: 0.5306 - val_acc: 0.7575
Epoch 10/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5283 - acc: 0.7527 - val_loss: 0.5223 - val_acc: 0.7628
Epoch 11/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5189 - acc: 0.7605 - val_loss: 0.5153 - val_acc: 0.7664
Epoch 12/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.5096 - acc: 0.7662 - val_loss: 0.5037 - val_acc: 0.7835
Epoch 13/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4990 - acc: 0.7799 - val_loss: 0.4920 - val_acc: 0.7876
Epoch 14/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4881 - acc: 0.7853 - val_loss: 0.4832 - val_acc: 0.7947
Epoch 15/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4779 - acc: 0.7864 - val_loss: 0.4709 - val_acc: 0.7988
Epoch 16/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4673 - acc: 0.7916 - val_loss: 0.4603 - val_acc: 0.8006
Epoch 17/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4570 - acc: 0.7941 - val_loss: 0.4567 - val_acc: 0.7982
Epoch 18/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4492 - acc: 0.7960 - val_loss: 0.4414 - val_acc: 0.8100
Epoch 19/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4366 - acc: 0.8027 - val_loss: 0.4343 - val_acc: 0.8106
Epoch 20/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4261 - acc: 0.8074 - val_loss: 0.4223 - val_acc: 0.8147
Epoch 21/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4168 - acc: 0.8075 - val_loss: 0.4157 - val_acc: 0.8183
Epoch 22/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.4061 - acc: 0.8142 - val_loss: 0.4017 - val_acc: 0.8224
Epoch 23/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3955 - acc: 0.8190 - val_loss: 0.3963 - val_acc: 0.8230
Epoch 24/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3876 - acc: 0.8245 - val_loss: 0.3853 - val_acc: 0.8307
Epoch 25/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3802 - acc: 0.8263 - val_loss: 0.3791 - val_acc: 0.8348
Epoch 26/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3700 - acc: 0.8323 - val_loss: 0.3757 - val_acc: 0.8342
Epoch 27/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3633 - acc: 0.8354 - val_loss: 0.3701 - val_acc: 0.8301
Epoch 28/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3569 - acc: 0.8389 - val_loss: 0.3589 - val_acc: 0.8372
Epoch 29/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3503 - acc: 0.8438 - val_loss: 0.3611 - val_acc: 0.8383
Epoch 30/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3446 - acc: 0.8429 - val_loss: 0.3505 - val_acc: 0.8478
Epoch 31/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3396 - acc: 0.8487 - val_loss: 0.3431 - val_acc: 0.8484
Epoch 32/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3326 - acc: 0.8507 - val_loss: 0.3391 - val_acc: 0.8501
Epoch 33/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3292 - acc: 0.8501 - val_loss: 0.3332 - val_acc: 0.8555
Epoch 34/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3236 - acc: 0.8552 - val_loss: 0.3320 - val_acc: 0.8484
Epoch 35/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3200 - acc: 0.8594 - val_loss: 0.3280 - val_acc: 0.8513
Epoch 36/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3155 - acc: 0.8614 - val_loss: 0.3287 - val_acc: 0.8519
Epoch 37/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3113 - acc: 0.8622 - val_loss: 0.3215 - val_acc: 0.8543
Epoch 38/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3100 - acc: 0.8608 - val_loss: 0.3236 - val_acc: 0.8513
Epoch 39/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3074 - acc: 0.8637 - val_loss: 0.3183 - val_acc: 0.8584
Epoch 40/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.3051 - acc: 0.8659 - val_loss: 0.3137 - val_acc: 0.8578
Epoch 41/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2998 - acc: 0.8667 - val_loss: 0.3133 - val_acc: 0.8590
Epoch 42/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2981 - acc: 0.8687 - val_loss: 0.3122 - val_acc: 0.8572
Epoch 43/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2966 - acc: 0.8698 - val_loss: 0.3149 - val_acc: 0.8519
Epoch 44/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2956 - acc: 0.8704 - val_loss: 0.3098 - val_acc: 0.8602
Epoch 45/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2926 - acc: 0.8693 - val_loss: 0.3026 - val_acc: 0.8596
Epoch 46/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2896 - acc: 0.8720 - val_loss: 0.3018 - val_acc: 0.8637
Epoch 47/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2872 - acc: 0.8705 - val_loss: 0.3024 - val_acc: 0.8625
Epoch 48/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2846 - acc: 0.8730 - val_loss: 0.2964 - val_acc: 0.8667
Epoch 49/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2872 - acc: 0.8724 - val_loss: 0.2981 - val_acc: 0.8631
Epoch 50/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2817 - acc: 0.8746 - val_loss: 0.2979 - val_acc: 0.8678
Epoch 51/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2816 - acc: 0.8729 - val_loss: 0.2936 - val_acc: 0.8678
Epoch 52/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2805 - acc: 0.8755 - val_loss: 0.2998 - val_acc: 0.8578
Epoch 53/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2810 - acc: 0.8749 - val_loss: 0.2936 - val_acc: 0.8696
Epoch 54/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2755 - acc: 0.8763 - val_loss: 0.2909 - val_acc: 0.8637
Epoch 55/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2756 - acc: 0.8743 - val_loss: 0.2925 - val_acc: 0.8673
Epoch 56/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2741 - acc: 0.8773 - val_loss: 0.2962 - val_acc: 0.8555
Epoch 57/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2739 - acc: 0.8740 - val_loss: 0.2869 - val_acc: 0.8708
Epoch 58/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2731 - acc: 0.8768 - val_loss: 0.2861 - val_acc: 0.8720
Epoch 59/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2699 - acc: 0.8783 - val_loss: 0.2902 - val_acc: 0.8655
Epoch 60/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2708 - acc: 0.8782 - val_loss: 0.2892 - val_acc: 0.8608
Epoch 61/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2686 - acc: 0.8792 - val_loss: 0.2851 - val_acc: 0.8714
Epoch 62/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2677 - acc: 0.8823 - val_loss: 0.2861 - val_acc: 0.8614
Epoch 63/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2677 - acc: 0.8789 - val_loss: 0.2880 - val_acc: 0.8661
Epoch 64/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2662 - acc: 0.8802 - val_loss: 0.2852 - val_acc: 0.8708
Epoch 65/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2656 - acc: 0.8804 - val_loss: 0.2937 - val_acc: 0.8596
Epoch 66/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2680 - acc: 0.8776 - val_loss: 0.2885 - val_acc: 0.8690
Epoch 67/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2653 - acc: 0.8799 - val_loss: 0.2815 - val_acc: 0.8743
Epoch 68/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2645 - acc: 0.8771 - val_loss: 0.2803 - val_acc: 0.8726
Epoch 69/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2626 - acc: 0.8805 - val_loss: 0.2861 - val_acc: 0.8637
Epoch 70/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2630 - acc: 0.8779 - val_loss: 0.2851 - val_acc: 0.8661
Epoch 71/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2621 - acc: 0.8786 - val_loss: 0.2794 - val_acc: 0.8737
Epoch 72/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2615 - acc: 0.8808 - val_loss: 0.2813 - val_acc: 0.8708
Epoch 73/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2609 - acc: 0.8823 - val_loss: 0.2799 - val_acc: 0.8726
Epoch 74/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2608 - acc: 0.8810 - val_loss: 0.2889 - val_acc: 0.8661
Epoch 75/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2592 - acc: 0.8808 - val_loss: 0.2756 - val_acc: 0.8743
Epoch 76/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2586 - acc: 0.8817 - val_loss: 0.2825 - val_acc: 0.8726
Epoch 77/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2593 - acc: 0.8816 - val_loss: 0.2845 - val_acc: 0.8678
Epoch 78/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2576 - acc: 0.8813 - val_loss: 0.2773 - val_acc: 0.8702
Epoch 79/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2569 - acc: 0.8822 - val_loss: 0.2777 - val_acc: 0.8743
Epoch 80/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2585 - acc: 0.8824 - val_loss: 0.2856 - val_acc: 0.8590
Epoch 81/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2564 - acc: 0.8791 - val_loss: 0.2777 - val_acc: 0.8726
Epoch 82/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2562 - acc: 0.8819 - val_loss: 0.2784 - val_acc: 0.8720
Epoch 83/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2568 - acc: 0.8808 - val_loss: 0.2817 - val_acc: 0.8720
Epoch 84/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2557 - acc: 0.8832 - val_loss: 0.2746 - val_acc: 0.8743
Epoch 85/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2560 - acc: 0.8792 - val_loss: 0.2761 - val_acc: 0.8743
Epoch 86/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2554 - acc: 0.8833 - val_loss: 0.2842 - val_acc: 0.8690
Epoch 87/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2535 - acc: 0.8841 - val_loss: 0.2760 - val_acc: 0.8702
Epoch 88/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2534 - acc: 0.8817 - val_loss: 0.2810 - val_acc: 0.8637
Epoch 89/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2534 - acc: 0.8829 - val_loss: 0.2717 - val_acc: 0.8773
Epoch 90/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2533 - acc: 0.8833 - val_loss: 0.2702 - val_acc: 0.8743
Epoch 91/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2527 - acc: 0.8835 - val_loss: 0.2790 - val_acc: 0.8714
Epoch 92/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2528 - acc: 0.8826 - val_loss: 0.2815 - val_acc: 0.8661
Epoch 93/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2539 - acc: 0.8822 - val_loss: 0.2730 - val_acc: 0.8761
Epoch 94/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2517 - acc: 0.8835 - val_loss: 0.2806 - val_acc: 0.8637
Epoch 95/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2510 - acc: 0.8838 - val_loss: 0.2721 - val_acc: 0.8773
Epoch 96/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2519 - acc: 0.8798 - val_loss: 0.2759 - val_acc: 0.8726
Epoch 97/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2504 - acc: 0.8838 - val_loss: 0.2744 - val_acc: 0.8726
Epoch 98/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2510 - acc: 0.8842 - val_loss: 0.2837 - val_acc: 0.8726
Epoch 99/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2522 - acc: 0.8836 - val_loss: 0.2720 - val_acc: 0.8737
Epoch 100/100
6780/6780 [==============================] - 0s 5us/step - loss: 0.2484 - acc: 0.8858 - val_loss: 0.2750 - val_acc: 0.8737
input_data.shape: (89, 20)
label_data.shape: (89, 2)
Data 0: no collision prob 0.04455 vs collision prob 0.95545
Data 1: no collision prob 0.26300 vs collision prob 0.73700
Data 2: no collision prob 0.03687 vs collision prob 0.96313
Data 3: no collision prob 0.15746 vs collision prob 0.84254
Data 4: no collision prob 0.29878 vs collision prob 0.70122
Data 5: no collision prob 1.00000 vs collision prob 0.00000
Data 6: no collision prob 0.99603 vs collision prob 0.00397
Data 7: no collision prob 0.99995 vs collision prob 0.00005
Data 8: no collision prob 0.96962 vs collision prob 0.03038
Data 9: no collision prob 0.32631 vs collision prob 0.67369
Data 10: no collision prob 0.99992 vs collision prob 0.00008
Data 11: no collision prob 0.99866 vs collision prob 0.00134
Data 12: no collision prob 0.06583 vs collision prob 0.93417
Data 13: no collision prob 0.99997 vs collision prob 0.00003
Data 14: no collision prob 0.27449 vs collision prob 0.72551
Data 15: no collision prob 0.36459 vs collision prob 0.63541
Data 16: no collision prob 0.03181 vs collision prob 0.96819
Data 17: no collision prob 0.97261 vs collision prob 0.02739
Data 18: no collision prob 0.99999 vs collision prob 0.00001
Data 19: no collision prob 0.24995 vs collision prob 0.75005
Data 20: no collision prob 0.94766 vs collision prob 0.05234
Data 21: no collision prob 0.99303 vs collision prob 0.00697
Data 22: no collision prob 0.93645 vs collision prob 0.06355
Data 23: no collision prob 0.99992 vs collision prob 0.00008
Data 24: no collision prob 0.99830 vs collision prob 0.00170
Data 25: no collision prob 0.99177 vs collision prob 0.00823
Data 26: no collision prob 0.99931 vs collision prob 0.00069
Data 27: no collision prob 0.23228 vs collision prob 0.76772
Data 28: no collision prob 0.23506 vs collision prob 0.76494
Data 29: no collision prob 0.27078 vs collision prob 0.72922
Data 30: no collision prob 0.17026 vs collision prob 0.82974
Data 31: no collision prob 0.99995 vs collision prob 0.00005
Data 32: no collision prob 0.82783 vs collision prob 0.17217
Data 33: no collision prob 0.99810 vs collision prob 0.00190
Data 34: no collision prob 0.14011 vs collision prob 0.85989
Data 35: no collision prob 0.98429 vs collision prob 0.01571
Data 36: no collision prob 0.03260 vs collision prob 0.96740
Data 37: no collision prob 0.99997 vs collision prob 0.00003
Data 38: no collision prob 0.25567 vs collision prob 0.74433
Data 39: no collision prob 0.99995 vs collision prob 0.00005
Data 40: no collision prob 0.99956 vs collision prob 0.00044
Data 41: no collision prob 0.99998 vs collision prob 0.00002
Data 42: no collision prob 0.12565 vs collision prob 0.87435
Data 43: no collision prob 0.99968 vs collision prob 0.00032
Data 44: no collision prob 0.99529 vs collision prob 0.00471
Data 45: no collision prob 0.52289 vs collision prob 0.47711
Data 46: no collision prob 0.99813 vs collision prob 0.00187
Data 47: no collision prob 0.28653 vs collision prob 0.71347
Data 48: no collision prob 0.99979 vs collision prob 0.00021
Data 49: no collision prob 0.99991 vs collision prob 0.00009
Data 50: no collision prob 0.99334 vs collision prob 0.00666
Data 51: no collision prob 1.00000 vs collision prob 0.00000
Data 52: no collision prob 0.03565 vs collision prob 0.96435
Data 53: no collision prob 0.99554 vs collision prob 0.00446
Data 54: no collision prob 0.18260 vs collision prob 0.81740
Data 55: no collision prob 0.98482 vs collision prob 0.01518
Data 56: no collision prob 0.85647 vs collision prob 0.14353
Data 57: no collision prob 0.95638 vs collision prob 0.04362
Data 58: no collision prob 0.27720 vs collision prob 0.72280
Data 59: no collision prob 0.99219 vs collision prob 0.00781
Data 60: no collision prob 0.99934 vs collision prob 0.00066
Data 61: no collision prob 0.28283 vs collision prob 0.71717
Data 62: no collision prob 0.99909 vs collision prob 0.00091
Data 63: no collision prob 0.99991 vs collision prob 0.00009
Data 64: no collision prob 0.12291 vs collision prob 0.87709
Data 65: no collision prob 0.97279 vs collision prob 0.02721
Data 66: no collision prob 0.07160 vs collision prob 0.92840
Data 67: no collision prob 0.99531 vs collision prob 0.00469
Data 68: no collision prob 0.99997 vs collision prob 0.00003
Data 69: no collision prob 0.02044 vs collision prob 0.97956
Data 70: no collision prob 0.02361 vs collision prob 0.97639
Data 71: no collision prob 0.98532 vs collision prob 0.01468
Data 72: no collision prob 0.26230 vs collision prob 0.73770
Data 73: no collision prob 0.02381 vs collision prob 0.97619
Data 74: no collision prob 0.70533 vs collision prob 0.29467
Data 75: no collision prob 0.99291 vs collision prob 0.00709
Data 76: no collision prob 0.99977 vs collision prob 0.00023
Data 77: no collision prob 0.28034 vs collision prob 0.71966
Data 78: no collision prob 1.00000 vs collision prob 0.00000
Data 79: no collision prob 0.06411 vs collision prob 0.93589
Data 80: no collision prob 1.00000 vs collision prob 0.00000
Data 81: no collision prob 0.99825 vs collision prob 0.00175
Data 82: no collision prob 0.99954 vs collision prob 0.00046
Data 83: no collision prob 1.00000 vs collision prob 0.00000
Data 84: no collision prob 0.26076 vs collision prob 0.73924
Data 85: no collision prob 0.99992 vs collision prob 0.00008
Data 86: no collision prob 1.00000 vs collision prob 0.00000
Data 87: no collision prob 0.99995 vs collision prob 0.00005
Data 88: no collision prob 0.99996 vs collision prob 0.00004

